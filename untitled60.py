# -*- coding: utf-8 -*-
"""Untitled60.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10xjZyaoFIy0xDW87OaM3YsNtkEkdEuDB

#Objetivo del proyecto: Este proyecto tiene cinco objetivos:

1.   Predecir si un cliente devolverá un producto o no.

2.   Predicción de churn: Utilizando las características de cada cliente y sus patrones de compra, podrías predecir la probabilidad de que un cliente se vuelva inactivo o deje de comprar en la plataforma. Esto se podría modelar como una tarea de clasificación binaria, donde el objetivo es la columna "Churn".

3. Segmentación de clientes: Usando clustering (no necesariamente un modelo de machine learning supervisado), podrías identificar segmentos de clientes en función de sus patrones de compra, categorías de productos, métodos de pago, etc. Luego, podrías utilizar un modelo de clasificación para predecir a qué segmento probablemente pertenezca un nuevo cliente.

4. Predicción de categoría de producto para futuras compras: Utilizando los datos históricos de compras, podrías intentar predecir la próxima categoría de producto que un cliente comprará. Esto podría ser útil para personalizar recomendaciones de productos.

5. Análisis de recurrencia de compras: Usando redes neuronales recurrentes, podrías modelar los patrones temporales de compra de los clientes para predecir cuándo realizarán su próxima compra. Esto implicaría hacer una serie temporal con la "Purchase Date" y otras variables relevantes, y ajustar el modelo para hacer predicciones a intervalos de tiempo.


Para el punto 2, trabajaremos con un dataset que tiene registros de compras de clientes de una e-commerce ficticia en la cuál, para poder realizar dichas compras, debes estar registrado con una especie de "membresia" y es por esto que, existe una columna en el dataset de entrenamiento que determina si el cliente abandonó el servicio o no.

##Para la opción 1 utlizaremos multiples modelos de ML y uno de Deep Learning con el fin de encontrar el mejor clasificador. Lista de los modelos a usar:

1.   Arbol de decisión
2.   KNN
3.   Random Forest
4.   XGBoost
5.  Redes Neuronales (Perceptron Multicapa)
6.   Redes Recurrentes
7.   Voting
8.   Stacking
"""

import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd
import numpy as np

from sklearn.metrics import f1_score,  recall_score, precision_score, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split


import tensorflow as tf
from tensorflow import keras

import xgboost as xgb
from tensorflow.keras import Sequential

#Configuración de parametros de Pandas para mejor visualización
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.max_colwidth', None)
pd.set_option('display.precision', 3)
pd.set_option('plotting.backend', 'matplotlib')
pd.options.mode.chained_assignment = None

# En produccion eliminar, se incluye por informacion
print(f'Pandas Version: {pd.__version__}')

dataset_ecommerce_customer_data_ratios = pd.read_csv('ecommerce_customer_data_custom_ratios.csv')

dataset_ecommerce_data_large = pd.read_csv('ecommerce_customer_data_large.csv')

"""##Analisis exploratorio de datos:"""

dataset_ecommerce_customer_data_ratios.head()

dataset_ecommerce_data_large.head()

"""Cual es el tamaño de los datasets?"""

dataset_ecommerce_customer_data_ratios.shape

dataset_ecommerce_data_large.shape

"""En total se reporta que por ahora, ambos datasets tienen un total de 250 mil filas y 13 columnas.

Ahora, haremos una copia a cada uno para poder usar a uno como dataset de entrenamiento y al otro de prueba:
"""

train_dataset_ecommerce = dataset_ecommerce_customer_data_ratios.copy()  # Conjunto de entrenamiento
test_dataset_ecommerce = dataset_ecommerce_data_large.copy()  # Conjunto de prueba

test_dataset_ecommerce = test_dataset_ecommerce.drop(columns=['Churn'])

# Verificar que la columna fue eliminada
test_dataset_ecommerce.head()

# Verificar que el conjunto de entrenamiento aún tiene la columna 'Churn'
train_dataset_ecommerce.head()

train_dataset_ecommerce.columns.tolist()

test_dataset_ecommerce.columns.tolist()

"""¿Que tipos de datos contiene cada columna?:"""

#La info del dataset de entrenamiento
train_dataset_ecommerce.info()

#La info del dataset de prueba
test_dataset_ecommerce.info()

"""¿Cuantas columnas de cada tipo de dato tenemos en cada dataframe?"""

train_dataset_ecommerce.dtypes.value_counts()

test_dataset_ecommerce.dtypes.value_counts()

"""Datos acerca de las columnas:

* Customer ID: Identificador único para cada cliente. Permite rastrear las compras individuales de cada cliente.

* Purchase Date: Fecha y hora de la compra realizada por el cliente. Útil para analizar la frecuencia y patrones temporales de las compras (Como tendencias estacionales o de horario).

* Product Category: Categoría del producto comprado (Ejemplo: "Electronics", "Home", "Clothing"). Ayuda a identificar que tipos de productos son más populares entre los clientes.


* Product Price: Precio unitario del producto comprado. Útil para calcular el gasto promedio por producto y el análisis de precios de diferentes categorías.


* Quantity: Cantidad de unidades compradas en cada transacción. Permite calcular el volumen de compra y puede indicar productos de alta demanda.

* Total Purchase Amount: El importe total gastado por el cliente en cada transacción. Es clave para analizar los ingresos generados en cada transacción.

* Payment Method: Método de pago utilizado en la compra (Ejemplo: "Credit Card", "PayPal", "Cash"). Útil para estudiar las preferencias de pago y posibles asociaciones con otros comportamientos de compra.

* Customer Age: Edad del cliente en el momento de la compra. Puede ayudar en la segmentación de clientes y en el análisis de patrones de compra según grupos etarios.

* Returns: Indica si la compra fue devuelta o no (0 = No, 1 = si). Esta columna es útil para estudiar patrones de devolución, identificar productos problemáticos, y analizar la satisfación del cliente.

* Customer Name: Nombre del cliente. Aunque no suele ser necesario en el análisis de datos, puede ser útil para validar los registros o para un análisis específico de clientes individuales.

* Age: Edad duplicada del cliente (aparentemente la misma que "Customer Age"). Podría ser redundante, pero conviene verificar si hay diferencias.

* Gender: Género del cliente ("Male" o "Female"). Ayuda en la segmentación de clientes y el análisis de patrones de compra según género.

* Churn: Una columna binaria que indica si el cliente ha abandonado el servicio (0 para retenido, 1 para abandonado). Esta variable es esencial para analizar la retención de clientes y desarrollar estrategias para reducir la tasa de abandono.

Mostramos los tipos de productos que hay:
"""

train_dataset_ecommerce['Product Category'].unique()

#Contamos el número de filas con 1 y 0 para las columnas 'Returns' y 'Churn' (Abandono):
devoluciones_count = train_dataset_ecommerce['Returns'].value_counts()
churn_count = train_dataset_ecommerce['Churn'].value_counts()
print(devoluciones_count)
print(churn_count)

"""###Analizamos la cantidad de valores faltantes que hay en cada dataset:

Para el dataset de entrenamiento:
"""

train_dataset_ecommerce.isnull().sum()

"""Para el dataset de prueba:"""

test_dataset_ecommerce.isnull().sum()

nan_returns_records = train_dataset_ecommerce[train_dataset_ecommerce['Returns'].isnull()]
nan_returns_records

"""###Hay valores duplicados?

Para el dataset de entrenamiento:
"""

train_dataset_ecommerce.duplicated().sum()

"""Para el dataset de prueba:"""

test_dataset_ecommerce.duplicated().sum()

"""###Calculamos la matriz de correlación:

Para el dataset de entrenamiento:
"""

# Seleccionar solo las columnas numéricas
numeric_columns = train_dataset_ecommerce.select_dtypes(include=np.number).columns

# Calcular la correlación solo para las columnas numéricas
correlation_matrix = train_dataset_ecommerce[numeric_columns].corr()
correlation_matrix

"""Para el dataset de prueba:"""

# Seleccionar solo las columnas numéricas
numeric_columns = test_dataset_ecommerce.select_dtypes(include=np.number).columns

# Calcular la correlación solo para las columnas numéricas
correlation_matrix_test = test_dataset_ecommerce[numeric_columns].corr()
correlation_matrix_test

"""Instrucciones para entender la correlación:
*   Los valores están en el rango de -1 a 1.

*   1 indica una correlación positiva perfecta (Cuando una variable aumenta, la otra también lo hace en proporción).

*   -1 indica una correlación negativa perfecta (Cuando una variable aumenta, la otra disminuye en proporción).

*   0 indica que no hay correlación lineal entre variables.

Dicho esto, podemos observar que en la gran mayoría de las variables, hay una correlación muy baja entre ellas, lo cual puede indicar que el dataset no tiene relaciones lineales fuertes entre muchas de sus características.Esto puede influir en la eleccion de los algoritmos, ya que modelos lineales podrían no capturar bien las relaciones entre las variables.

Las únicas excepciones con correlación medianamente alta entre variables son Age con Customer Age, Customer Age con Total Amount Purchase y Product Price con Total Amount Purchase (Estos dos últimos casos tienen dicha correlación medianamente alta solamente en el dataset de prueba). Para el primer caso, tiene una correlación de 1, lo que indica que Customer Age y Age probablemente sean duplicados o esten altamente relacionados, ya que ambos representan la edad del cliente al momento de la compra. Esto podría ser redundante, asi que vamos a eliminar una de ellas.

###Calculamos las medidas de resumen para las variables cuantitativas (Media, mediana, moda, etc.):

Para el dataset de entrenamiento:
"""

train_dataset_ecommerce.describe()

"""Para el dataset de prueba:"""

test_dataset_ecommerce.describe()

"""##Visualización de datos:"""

